name: Autonomous QA Testing with Auto-Fix PRs

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  issues: write

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-html pytest-asyncio httpx
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi
    
    - name: Install Playwright
      run: |
        pip install playwright
        playwright install chromium
        playwright install-deps chromium
    
    - name: Install Frontend dependencies
      run: |
        if [ -f frontend/package.json ]; then
          cd frontend
          npm install
          cd ..
        fi
    
    - name: Initialize Database
      run: |
        python prestart.py || echo "Prestart script not found or failed"
    
    - name: Run Unit Tests with Coverage
      id: unit_tests
      continue-on-error: true
      run: |
        pytest tests/ --cov=backend --cov=database --cov-report=xml --cov-report=html --cov-report=term -v > test_output.txt 2>&1
        echo "::set-output name=exit_code::$?"
        cat test_output.txt
    
    - name: Upload Coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
        verbose: true
    
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results
        path: |
          coverage.xml
          htmlcov/
          test_output.txt
          report.html
    
    - name: Analyze Test Failures
      if: steps.unit_tests.outputs.exit_code != '0'
      id: analyze_failures
      run: |
        echo "## Test Failure Analysis" > failure_analysis.md
        echo "" >> failure_analysis.md
        echo "### Failed Tests:" >> failure_analysis.md
        grep "FAILED" test_output.txt >> failure_analysis.md || echo "No failure details available" >> failure_analysis.md
        echo "" >> failure_analysis.md
        echo "### Suggested Fixes:" >> failure_analysis.md
        echo "1. Review assertion statements in failing tests" >> failure_analysis.md
        echo "2. Check if implementation has changed without updating tests" >> failure_analysis.md
        echo "3. Verify test fixtures and mock data" >> failure_analysis.md
        echo "4. Ensure all dependencies are properly installed" >> failure_analysis.md
    
    - name: Create Fix Branch
      if: steps.unit_tests.outputs.exit_code != '0' && github.event_name == 'push'
      id: create_branch
      run: |
        BRANCH_NAME="qa-council/auto-fix-$(date +%Y%m%d-%H%M%S)"
        git config user.name "QA Council Bot"
        git config user.email "qa-council@github-actions"
        git checkout -b $BRANCH_NAME
        echo "BRANCH_NAME=$BRANCH_NAME" >> $GITHUB_OUTPUT
    
    - name: Generate Test Fixes
      if: steps.unit_tests.outputs.exit_code != '0' && github.event_name == 'push'
      run: |
        # Create a fixes documentation file
        cat > TEST_FIXES.md << 'EOF'
        # Automated Test Fix Recommendations
        
        ## Overview
        The QA Council has analyzed test failures and generated fix recommendations.
        
        ## Test Execution Summary
        - **Status**: Some tests failed
        - **Coverage**: See coverage report for details
        - **Timestamp**: $(date)
        
        ## Recommended Fixes
        
        ### 1. Review Test Assertions
        Check if expected values match actual implementation behavior.
        
        ### 2. Update Test Data
        Ensure fixtures and test data are current with schema changes.
        
        ### 3. Check Dependencies
        Verify all required packages are in requirements.txt
        
        ### 4. Inspect Error Messages
        See test_output.txt for detailed failure information.
        
        ## Next Steps
        1. Review failures in test_output.txt
        2. Apply recommended fixes
        3. Run tests locally: `pytest -v`
        4. Commit and push fixes
        
        ---
        *Generated by QA Council Autonomous Testing System*
        EOF
        
        git add TEST_FIXES.md
        git commit -m "docs: Add automated test fix recommendations" || echo "No changes to commit"
    
    - name: Push Fix Branch
      if: steps.unit_tests.outputs.exit_code != '0' && github.event_name == 'push'
      run: |
        git push origin ${{ steps.create_branch.outputs.BRANCH_NAME }} || echo "Push failed"
    
    - name: Create Pull Request with Fixes
      if: steps.unit_tests.outputs.exit_code != '0' && github.event_name == 'push'
      uses: peter-evans/create-pull-request@v5
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        branch: ${{ steps.create_branch.outputs.BRANCH_NAME }}
        base: ${{ github.ref_name }}
        title: "ü§ñ Automated Test Fix Recommendations"
        body: |
          ## ü§ñ QA Council - Automated Analysis
          
          This PR contains test failure analysis and fix recommendations from the QA Council autonomous testing system.
          
          ### üìä Test Results
          - Some tests failed during the latest run
          - Detailed analysis available in TEST_FIXES.md
          - Coverage report uploaded as artifact
          
          ### üîç Analysis
          The QA Council has analyzed the failures and identified potential issues:
          - Review test assertions
          - Check for implementation changes
          - Verify test data and fixtures
          - Ensure dependencies are current
          
          ### üìã Files Changed
          - `TEST_FIXES.md` - Detailed fix recommendations
          
          ### ‚úÖ Next Steps
          1. Review the recommendations in TEST_FIXES.md
          2. Check test_output.txt artifact for details
          3. Apply fixes to failing tests
          4. Run tests locally to verify
          5. Update this PR with fixes or create a new one
          
          ### üìà Coverage Report
          View the coverage report in the Actions artifacts.
          
          ---
          **Generated by:** QA Council Autonomous Testing System  
          **Trigger:** ${{ github.event_name }} on ${{ github.ref_name }}  
          **Run ID:** ${{ github.run_id }}
        labels: |
          automated
          testing
          qa-council
        assignees: ${{ github.actor }}
    
    - name: Comment on PR (if PR event)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          let testOutput = '';
          try {
            testOutput = fs.readFileSync('test_output.txt', 'utf8');
          } catch (e) {
            testOutput = 'Test output not available';
          }
          
          const passed = (testOutput.match(/passed/g) || []).length;
          const failed = (testOutput.match(/FAILED/g) || []).length;
          const coverageMatch = testOutput.match(/TOTAL\s+\d+\s+\d+\s+(\d+)%/);
          const coverage = coverageMatch ? coverageMatch[1] : 'N/A';
          
          const body = `## ü§ñ QA Council Test Report
          
          ### üìä Test Results
          - ‚úÖ Passed: ${passed}
          - ‚ùå Failed: ${failed}
          - üìà Coverage: ${coverage}%
          
          ### üîó Details
          - Full test output available in Actions artifacts
          - Coverage report uploaded to Codecov
          
          ${failed > 0 ? '### ‚ö†Ô∏è Action Required\nSome tests failed. Review the failures and apply fixes.' : '### ‚úÖ All Tests Passing\nGreat job! All tests are passing.'}
          
          ---
          *Automated comment by QA Council*`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });
    
    - name: Fail workflow if tests failed
      if: steps.unit_tests.outputs.exit_code != '0'
      run: |
        echo "::error::Tests failed. See test output and fix recommendations."
        exit 1

  e2e-tests:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi
        pip install playwright pytest
        playwright install chromium
        playwright install-deps chromium
    
    - name: Start Backend
      run: |
        cd backend
        python -m uvicorn main:app --host 0.0.0.0 --port 8000 &
        sleep 5
    
    - name: Start Frontend
      run: |
        cd frontend
        npm install
        npm start &
        sleep 10
    
    - name: Run E2E Tests
      run: |
        pytest tests/e2e/ -v --headed=false
    
    - name: Upload E2E Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-results
        path: |
          tests/e2e/screenshots/
          tests/e2e/videos/
